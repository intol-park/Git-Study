{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_shape': [13], 'hidden_units': [64, 32], 'epochs': 10, 'batch_size': 32, 'learning_rate': 0.001}\n",
      "{'input_shape': [128, 1], 'conv_layers': [{'filters': 32, 'kernel_size': 3, 'activation': 'relu'}, {'filters': 64, 'kernel_size': 3, 'activation': 'relu'}], 'dense_units': 64, 'epochs': 10, 'batch_size': 32, 'learning_rate': 0.001}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\intol\\anaconda3\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 1.3968 - mae: 0.8914\n",
      "Epoch 2/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8105 - mae: 0.6423  \n",
      "Epoch 3/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4649 - mae: 0.4569 \n",
      "Epoch 4/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3906 - mae: 0.3915 \n",
      "Epoch 5/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2663 - mae: 0.3502 \n",
      "Epoch 6/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2263 - mae: 0.3293 \n",
      "Epoch 7/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2098 - mae: 0.3049 \n",
      "Epoch 8/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1907 - mae: 0.2898 \n",
      "Epoch 9/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1403 - mae: 0.2521 \n",
      "Epoch 10/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1117 - mae: 0.2435 \n",
      "Epoch 1/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.9416 - mae: 0.7090\n",
      "Epoch 2/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.7579 - mae: 0.6691\n",
      "Epoch 3/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5601 - mae: 0.5308 \n",
      "Epoch 4/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.3963 - mae: 0.4272\n",
      "Epoch 5/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3403 - mae: 0.3715 \n",
      "Epoch 6/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2338 - mae: 0.3132\n",
      "Epoch 7/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3193 - mae: 0.3779 \n",
      "Epoch 8/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3316 - mae: 0.3531\n",
      "Epoch 9/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2414 - mae: 0.3247 \n",
      "Epoch 10/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2246 - mae: 0.3245 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\intol\\anaconda3\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 14 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "c:\\Users\\intol\\anaconda3\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 18 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1.0751 - mae: 0.7434  \n",
      "Loaded regression model evaluation - Loss: 1.130346655845642, MAE: 0.7700888514518738\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.8906 - mae: 0.6842  \n",
      "Loaded CNN1D regression model evaluation - Loss: 0.9631533026695251, MAE: 0.7175201773643494\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "     True Values  Regression Predictions  CNN1D Predictions  RMSE Regression  \\\n",
      "0            7.2               25.346943          23.302929         9.780208   \n",
      "1           18.8               22.086683          22.790236         9.780208   \n",
      "2           19.0               20.378542          23.037464         9.780208   \n",
      "3           27.0               21.656462          24.511843         9.780208   \n",
      "4           22.2               22.898540          23.093573         9.780208   \n",
      "..           ...                     ...                ...              ...   \n",
      "97          21.9               19.587240          23.880819         9.780208   \n",
      "98          24.1               20.388559          23.022255         9.780208   \n",
      "99          50.0               20.211206          24.275002         9.780208   \n",
      "100         26.7               21.818850          25.493532         9.780208   \n",
      "101         25.0               22.746326          23.110123         9.780208   \n",
      "\n",
      "     R2 Regression  RMSE CNN1D  R2 CNN1D  \n",
      "0        -0.149064    9.027968  0.020898  \n",
      "1        -0.149064    9.027968  0.020898  \n",
      "2        -0.149064    9.027968  0.020898  \n",
      "3        -0.149064    9.027968  0.020898  \n",
      "4        -0.149064    9.027968  0.020898  \n",
      "..             ...         ...       ...  \n",
      "97       -0.149064    9.027968  0.020898  \n",
      "98       -0.149064    9.027968  0.020898  \n",
      "99       -0.149064    9.027968  0.020898  \n",
      "100      -0.149064    9.027968  0.020898  \n",
      "101      -0.149064    9.027968  0.020898  \n",
      "\n",
      "[102 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from models import *\n",
    "from datasets import *\n",
    "import json\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def load_config(config_path):\n",
    "    with open(config_path, 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "    return config\n",
    "\n",
    "def normalize_data(x_train, x_test):\n",
    "    mean = np.mean(x_train, axis=0)\n",
    "    std = np.std(x_train, axis=0)\n",
    "    x_train_norm = (x_train - mean) / std\n",
    "    x_test_norm = (x_test - mean) / std\n",
    "    return x_train_norm, x_test_norm, mean, std\n",
    "\n",
    "def main():\n",
    "    # Load configurations\n",
    "    regression_config = load_config('configs/regression.yaml')\n",
    "    cnn1d_regression_config = load_config('configs/cnn1d_regression.yaml')\n",
    "    print(regression_config)\n",
    "    print(cnn1d_regression_config)\n",
    "\n",
    "    # Initialize models\n",
    "    regression_model = RegressionModel(regression_config)\n",
    "    cnn1d_regression_model = CNN1DRegressionModel(cnn1d_regression_config)\n",
    "\n",
    "    # Load dataset (using synthetic data for 1D CNN example)\n",
    "    (x_train, y_train), (x_test, y_test) = load_dataset('boston_housing')\n",
    "\n",
    "    # Normalize data\n",
    "    x_train, x_test, x_mean, x_std = normalize_data(x_train, x_test)\n",
    "    y_mean = np.mean(y_train)\n",
    "    y_std = np.std(y_train)\n",
    "    y_train = (y_train - y_mean) / y_std\n",
    "    y_test = (y_test - y_mean) / y_std\n",
    "\n",
    "    # Reshape data for 1D CNN (example only)\n",
    "    x_train_cnn1d = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n",
    "    x_test_cnn1d = x_test.reshape((x_test.shape[0], x_test.shape[1], 1))\n",
    "\n",
    "    # Build models with input shape\n",
    "    regression_model.build(x_train.shape[1:])\n",
    "    cnn1d_regression_model.build(x_train_cnn1d.shape[1:])\n",
    "    \n",
    "    save_model_path = \"results/saved_models\"\n",
    "    os.makedirs(save_model_path, exist_ok=True)  # Ensure the save directory exists\n",
    "\n",
    "    # Compile and train regression model\n",
    "    regression_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=regression_config['learning_rate']),\n",
    "                             loss='mse',\n",
    "                             metrics=['mae'])\n",
    "    regression_model.fit(x_train, y_train, epochs=regression_config['epochs'], batch_size=regression_config['batch_size'])\n",
    "    regression_model.save(os.path.join(save_model_path, 'regression.keras'))\n",
    "    regression_save_config = regression_model.get_config()\n",
    "    with open(os.path.join(save_model_path, 'regression_config.json'), 'w') as f:\n",
    "        json.dump(regression_save_config, f)\n",
    "\n",
    "    # Compile and train CNN1D regression model\n",
    "    cnn1d_regression_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=cnn1d_regression_config['learning_rate']),\n",
    "                                   loss='mse',\n",
    "                                   metrics=['mae'])\n",
    "    cnn1d_regression_model.fit(x_train_cnn1d, y_train, epochs=cnn1d_regression_config['epochs'], batch_size=cnn1d_regression_config['batch_size'])\n",
    "    cnn1d_regression_model.save(os.path.join(save_model_path, 'cnn1d_regression.keras'))\n",
    "    cnn1d_save_config = cnn1d_regression_model.get_config()\n",
    "    with open(os.path.join(save_model_path, 'cnn1d_regression_config.json'), 'w') as f:\n",
    "        json.dump(cnn1d_save_config, f)\n",
    "\n",
    "    # Load models\n",
    "    loaded_regression_model = tf.keras.models.load_model(\n",
    "        os.path.join(save_model_path, 'regression.keras'), custom_objects={\"RegressionModel\": RegressionModel})\n",
    "    loaded_cnn1d_regression_model = tf.keras.models.load_model(\n",
    "        os.path.join(save_model_path, 'cnn1d_regression.keras'), custom_objects={\"CNN1DRegressionModel\": CNN1DRegressionModel})\n",
    "\n",
    "\n",
    "    # Evaluate loaded models\n",
    "    loaded_regression_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=regression_config['learning_rate']),\n",
    "                                    loss='mse',\n",
    "                                    metrics=['mae'])\n",
    "    loss, mae = loaded_regression_model.evaluate(x_test, y_test)\n",
    "    print(f'Loaded regression model evaluation - Loss: {loss}, MAE: {mae}')\n",
    "\n",
    "    loaded_cnn1d_regression_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=cnn1d_regression_config['learning_rate']),\n",
    "                                          loss='mse',\n",
    "                                          metrics=['mae'])\n",
    "    loss, mae = loaded_cnn1d_regression_model.evaluate(x_test_cnn1d, y_test)\n",
    "    print(f'Loaded CNN1D regression model evaluation - Loss: {loss}, MAE: {mae}')\n",
    "\n",
    "    # 예측 수행 및 결과 출력\n",
    "    save_csv_path = \"results/csv/\"\n",
    "    os.makedirs(save_csv_path, exist_ok=True)\n",
    "    y_pred_regression = loaded_regression_model.predict(x_test)\n",
    "    y_pred_cnn1d = loaded_cnn1d_regression_model.predict(x_test_cnn1d)\n",
    "\n",
    "    # Un-normalize predictions\n",
    "    y_pred_regression = y_pred_regression * y_std + y_mean\n",
    "    y_pred_cnn1d = y_pred_cnn1d * y_std + y_mean\n",
    "    y_test = y_test * y_std + y_mean\n",
    "\n",
    "    # Calculate RMSE and R-squared for regression model\n",
    "    rmse_regression = mean_squared_error(y_test, y_pred_regression, squared=False)\n",
    "    r2_regression = r2_score(y_test, y_pred_regression)\n",
    "\n",
    "    # Calculate RMSE and R-squared for CNN1D regression model\n",
    "    rmse_cnn1d = mean_squared_error(y_test, y_pred_cnn1d, squared=False)\n",
    "    r2_cnn1d = r2_score(y_test, y_pred_cnn1d)\n",
    "\n",
    "    # Create DataFrame to store evaluation results\n",
    "    results = pd.DataFrame({\n",
    "        'True Values': y_test,\n",
    "        'Regression Predictions': y_pred_regression.flatten(),\n",
    "        'CNN1D Predictions': y_pred_cnn1d.flatten()\n",
    "    })\n",
    "    results['RMSE Regression'] = rmse_regression\n",
    "    results['R2 Regression'] = r2_regression\n",
    "    results['RMSE CNN1D'] = rmse_cnn1d\n",
    "    results['R2 CNN1D'] = r2_cnn1d\n",
    "\n",
    "    # Save results to a CSV file\n",
    "    results.to_csv(os.path.join(save_csv_path, 'evaluation_results.csv'), index=False)\n",
    "\n",
    "    print(results)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_shape': [13], 'hidden_units': [64, 32], 'epochs': 10, 'batch_size': 32, 'learning_rate': 0.001}\n",
      "{'input_shape': [128, 1], 'conv_layers': [{'filters': 32, 'kernel_size': 3, 'activation': 'relu'}, {'filters': 64, 'kernel_size': 3, 'activation': 'relu'}], 'dense_units': 64, 'epochs': 10, 'batch_size': 32, 'learning_rate': 0.001}\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\intol\\anaconda3\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2488.2209 - mae: 42.2477\n",
      "Epoch 2/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 414.5920 - mae: 16.6828 \n",
      "Epoch 3/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 176.7500 - mae: 10.1440\n",
      "Epoch 4/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 93.4134 - mae: 8.0197  \n",
      "Epoch 5/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 69.6727 - mae: 5.3250 \n",
      "Epoch 6/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 71.4398 - mae: 6.4811  \n",
      "Epoch 7/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 57.8991 - mae: 5.1696 \n",
      "Epoch 8/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 51.6760 - mae: 5.1570 \n",
      "Epoch 9/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 48.8677 - mae: 4.9212 \n",
      "Epoch 10/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 59.6542 - mae: 5.5043 \n",
      "Epoch 1/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 211.7507 - mae: 11.9977\n",
      "Epoch 2/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 174.1114 - mae: 10.8981\n",
      "Epoch 3/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 153.4632 - mae: 9.9521 \n",
      "Epoch 4/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 129.8718 - mae: 9.2908 \n",
      "Epoch 5/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 110.4263 - mae: 8.1206\n",
      "Epoch 6/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 98.8095 - mae: 7.8463 \n",
      "Epoch 7/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 101.7759 - mae: 7.9914 \n",
      "Epoch 8/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 94.1535 - mae: 7.5896  \n",
      "Epoch 9/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 87.8068 - mae: 7.3122  \n",
      "Epoch 10/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 76.0076 - mae: 6.4657 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\intol\\anaconda3\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 14 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "c:\\Users\\intol\\anaconda3\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 18 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1018.8917 - mae: 27.1748  \n",
      "Loaded regression model evaluation - Loss: 989.7361450195312, MAE: 26.361289978027344\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 320.1386 - mae: 15.0547  \n",
      "Loaded CNN1D regression model evaluation - Loss: 343.90093994140625, MAE: 15.682975769042969\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000019F11521D80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 51ms/stepWARNING:tensorflow:6 out of the last 12 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000019F11521D80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "     True Values  Regression Predictions  CNN1D Predictions  RMSE Regression  \\\n",
      "0            7.2               64.652458          13.891747        31.460072   \n",
      "1           18.8               50.240692          10.154907        31.460072   \n",
      "2           19.0               35.644089           4.789661        31.460072   \n",
      "3           27.0               45.293480           9.762479        31.460072   \n",
      "4           22.2               37.676868           5.721700        31.460072   \n",
      "..           ...                     ...                ...              ...   \n",
      "97          21.9               63.659801          13.227545        31.460072   \n",
      "98          24.1               50.318531           5.148750        31.460072   \n",
      "99          50.0               46.848373           9.803375        31.460072   \n",
      "100         26.7               41.393501           7.221749        31.460072   \n",
      "101         25.0               37.303524           9.649592        31.460072   \n",
      "\n",
      "     R2 Regression  RMSE CNN1D  R2 CNN1D  \n",
      "0       -10.889601   18.544566 -3.131247  \n",
      "1       -10.889601   18.544566 -3.131247  \n",
      "2       -10.889601   18.544566 -3.131247  \n",
      "3       -10.889601   18.544566 -3.131247  \n",
      "4       -10.889601   18.544566 -3.131247  \n",
      "..             ...         ...       ...  \n",
      "97      -10.889601   18.544566 -3.131247  \n",
      "98      -10.889601   18.544566 -3.131247  \n",
      "99      -10.889601   18.544566 -3.131247  \n",
      "100     -10.889601   18.544566 -3.131247  \n",
      "101     -10.889601   18.544566 -3.131247  \n",
      "\n",
      "[102 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from models import *\n",
    "from datasets import *\n",
    "import json\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pandas as pd\n",
    "\n",
    "def load_config(config_path):\n",
    "    with open(config_path, 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "    return config\n",
    "\n",
    "def main():\n",
    "    # Load configurations\n",
    "    regression_config = load_config('configs/regression.yaml')\n",
    "    cnn1d_regression_config = load_config('configs/cnn1d_regression.yaml')\n",
    "    print(regression_config)\n",
    "    print(cnn1d_regression_config)\n",
    "\n",
    "    # Initialize models\n",
    "    regression_model = RegressionModel(regression_config)\n",
    "    cnn1d_regression_model = CNN1DRegressionModel(cnn1d_regression_config)\n",
    "\n",
    "    # Load dataset (using synthetic data for 1D CNN example)\n",
    "    (x_train, y_train), (x_test, y_test) = load_dataset('boston_housing')\n",
    "\n",
    "    # Reshape data for 1D CNN (example only)\n",
    "    x_train_cnn1d = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n",
    "    x_test_cnn1d = x_test.reshape((x_test.shape[0], x_test.shape[1], 1))\n",
    "\n",
    "    # Build models with input shape\n",
    "    regression_model.build(x_train.shape[1:])\n",
    "    cnn1d_regression_model.build(x_train_cnn1d.shape[1:])\n",
    "    \n",
    "    save_model_path = \"results/saved_models\"\n",
    "    os.makedirs(save_model_path, exist_ok=True)  # Ensure the save directory exists\n",
    "\n",
    "    # Compile and train regression model\n",
    "    regression_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=regression_config['learning_rate']),\n",
    "                             loss='mse',\n",
    "                             metrics=['mae'])\n",
    "    regression_model.fit(x_train, y_train, epochs=regression_config['epochs'], batch_size=regression_config['batch_size'])\n",
    "    regression_model.save(os.path.join(save_model_path, 'regression.keras'))\n",
    "    regression_save_config = regression_model.get_config()\n",
    "    with open(os.path.join(save_model_path, 'regression_config.json'), 'w') as f:\n",
    "        json.dump(regression_save_config, f)\n",
    "\n",
    "    # Compile and train CNN1D regression model\n",
    "    cnn1d_regression_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=cnn1d_regression_config['learning_rate']),\n",
    "                                   loss='mse',\n",
    "                                   metrics=['mae'])\n",
    "    cnn1d_regression_model.fit(x_train_cnn1d, y_train, epochs=cnn1d_regression_config['epochs'], batch_size=cnn1d_regression_config['batch_size'])\n",
    "    cnn1d_regression_model.save(os.path.join(save_model_path, 'cnn1d_regression.keras'))\n",
    "    cnn1d_save_config = cnn1d_regression_model.get_config()\n",
    "    with open(os.path.join(save_model_path, 'cnn1d_regression_config.json'), 'w') as f:\n",
    "        json.dump(cnn1d_save_config, f)\n",
    "\n",
    "    # Load models\n",
    "    loaded_regression_model = tf.keras.models.load_model(\n",
    "        os.path.join(save_model_path, 'regression.keras'), custom_objects={\"RegressionModel\": RegressionModel})\n",
    "    loaded_cnn1d_regression_model = tf.keras.models.load_model(\n",
    "        os.path.join(save_model_path, 'cnn1d_regression.keras'), custom_objects={\"CNN1DRegressionModel\": CNN1DRegressionModel})\n",
    "\n",
    "\n",
    "    # Evaluate loaded models\n",
    "    loaded_regression_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=regression_config['learning_rate']),\n",
    "                                    loss='mse',\n",
    "                                    metrics=['mae'])\n",
    "    loss, mae = loaded_regression_model.evaluate(x_test, y_test)\n",
    "    print(f'Loaded regression model evaluation - Loss: {loss}, MAE: {mae}')\n",
    "\n",
    "    loaded_cnn1d_regression_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=cnn1d_regression_config['learning_rate']),\n",
    "                                          loss='mse',\n",
    "                                          metrics=['mae'])\n",
    "    loss, mae = loaded_cnn1d_regression_model.evaluate(x_test_cnn1d, y_test)\n",
    "    print(f'Loaded CNN1D regression model evaluation - Loss: {loss}, MAE: {mae}')\n",
    "\n",
    "    # 예측 수행 및 결과 출력\n",
    "    save_csv_path = \"results/csv/\"\n",
    "    os.makedirs(save_csv_path, exist_ok=True)\n",
    "    y_pred_regression = loaded_regression_model.predict(x_test)\n",
    "    y_pred_cnn1d = loaded_cnn1d_regression_model.predict(x_test_cnn1d)\n",
    "\n",
    "    # Calculate RMSE and R-squared for regression model\n",
    "    rmse_regression = mean_squared_error(y_test, y_pred_regression, squared=False)\n",
    "    r2_regression = r2_score(y_test, y_pred_regression)\n",
    "\n",
    "    # Calculate RMSE and R-squared for CNN1D regression model\n",
    "    rmse_cnn1d = mean_squared_error(y_test, y_pred_cnn1d, squared=False)\n",
    "    r2_cnn1d = r2_score(y_test, y_pred_cnn1d)\n",
    "\n",
    "    # Create DataFrame to store evaluation results\n",
    "    results = pd.DataFrame({\n",
    "        'True Values': y_test,\n",
    "        'Regression Predictions': y_pred_regression.flatten(),\n",
    "        'CNN1D Predictions': y_pred_cnn1d.flatten()\n",
    "    })\n",
    "    results['RMSE Regression'] = rmse_regression\n",
    "    results['R2 Regression'] = r2_regression\n",
    "    results['RMSE CNN1D'] = rmse_cnn1d\n",
    "    results['R2 CNN1D'] = r2_cnn1d\n",
    "\n",
    "    # Save results to a CSV file\n",
    "    results.to_csv(os.path.join(save_csv_path, 'evaluation_results.csv'), index=False)\n",
    "\n",
    "    print(results)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
